{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the size of the datasets on disk\n",
    "For the manuscript on the fishes, we want to know how much data we produced.\n",
    "This notebook is based on a copy of `DataWrangling.ipynb` and https://github.com/habi/zmk-tooth-cohort/blob/master/ToothDataSize.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import os\n",
    "import glob\n",
    "import pandas\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The canonical place for *this* notebook is the iee research storage, as only there we have *all* the data\n",
    "if 'Linux' in platform.system():\n",
    "    Root = os.path.join(os.sep, 'home', 'habi', 'research-storage-iee', 'microCT')\n",
    "else:\n",
    "    Root = os.path.join('I:\\\\microCTupload')\n",
    "print('We are loading all the data from %s' % Root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make us a dataframe for saving all that we need\n",
    "Data = pandas.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get *all* log files, unsorted but fast\n",
    "Data['LogFile'] = [os.path.join(root, name)\n",
    "                   for root, dirs, files in os.walk(Root)\n",
    "                   for name in files\n",
    "                   if name.endswith((\".log\"))]\n",
    "print('We have %s log files to work with' % (len(Data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all folders\n",
    "Data['Folder'] = [os.path.dirname(f) for f in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we look for *all* log files, we have a lot of duplicated folder\n",
    "# Do some deduplication as further down we look for files in *folders*\n",
    "Data.drop_duplicates(subset=['Folder'], inplace=True)\n",
    "Data = Data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate us some meaningful colums\n",
    "Data['Fish'] = [l[len(Root) + 1:].split(os.sep)[0] for l in Data['LogFile']]\n",
    "Data['Scan'] = ['.'.join(l[len(Root) + 1:].split(os.sep)[1:-1]) for l in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_machine(logfile):\n",
    "    \"\"\"Get the machine we used to scan\"\"\"\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Scanner' in line:\n",
    "                machine = line.split('=')[1].strip()\n",
    "    return(machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Scanner'] = [get_machine(log) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The iee research storage folder contains some folders with scans done by Kassandra on a SkyScan1273.\n",
    "# Exclude those, since they are not part of this study, we just looked at them to help her.\n",
    "for c, row in Data.iterrows():\n",
    "    if '1273' in row.Scanner:\n",
    "        print('Dropping %s from our dataframe' % row.LogFile[len(Root)+1:])\n",
    "        Data.drop([c], inplace=True)\n",
    "# Reset dataframe index\n",
    "Data = Data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The iee research storage folder contains folders with scans of only teeth, done as pilot\n",
    "# Exclude those, since they are not part of this study.\n",
    "for c, row in Data.iterrows():\n",
    "    if 'Teeth' in row.Folder:\n",
    "        print('Dropping %s from our dataframe' % row.LogFile[len(Root)+1:])\n",
    "        Data.drop([c], inplace=True)\n",
    "# Reset dataframe index\n",
    "Data = Data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many fishes did we scan?\n",
    "# We scanned six 'buckets of fish', so subtract those :)\n",
    "print('We have %s unique fish names in our corpus of scans' % (len(Data.Fish.unique()) - 6))\n",
    "print('We have %s different proj and rec folders in total' % len(Data.Scan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily drop some data\n",
    "# Data = Data[:3]\n",
    "# print('We are currently working with a subset of %s teeth' % len(Data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the projection details\n",
    "# Let's look for 'tif' *and* 'iif' files, which are alignment projections\n",
    "# Get the file names of the projections\n",
    "Data['Projections'] = [[os.path.join(root, name)\n",
    "                        for root, dirs, files in os.walk(f)\n",
    "                        for name in files\n",
    "                        if name.endswith((\"if\"))] for f in Data['Folder']]\n",
    "# Count how many files we have\n",
    "Data['NumberOfProjections'] = [len(r) for r in Data.Projections]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the size of the TIFFs\n",
    "Data['ProjectionSize'] = [[os.path.getsize(proj) for proj in projections] for projections in Data['Projections']]\n",
    "Data['ProjectionSizeSum'] = [sum(size) for size in Data['ProjectionSize']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('In total, all projections are %0.2f GB in size' % (Data['ProjectionSizeSum'].sum() / 1024 / 1024 / 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('In total, all projections are %0.1f TB in size' % (Data['ProjectionSizeSum'].sum() / 1024 / 1024 / 1024 / 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data[['Folder', 'NumberOfProjections', 'ProjectionSize', 'ProjectionSizeSum']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get (nearly) the same size, use\n",
    "````bash\n",
    "find . -iname '*.?if' -print0 | du -ch --files0-from=-\n",
    "````\n",
    "in a Linux console.\n",
    "The command is based on https://askubuntu.com/a/558989/759778"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the file names of the reconstructions\n",
    "Data['Reconstructions'] = [[os.path.join(root, name)\n",
    "                            for root, dirs, files in os.walk(f)\n",
    "                            for name in files\n",
    "                            if 'rec0' in name and name.endswith((\".png\"))] for f in Data['Folder']]\n",
    "# Count how many files we have\n",
    "Data['NumberOfReconstructions'] = [len(r) for r in Data.Reconstructions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We have a total of %s reconstructions on %s' % (Data['NumberOfReconstructions'].sum(), Root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This is about %s reconstructions per scan (%s scans, %s fishes)' % (round(Data['NumberOfReconstructions'].sum() / len(Data[Data['NumberOfReconstructions'] > 0])),\n",
    "                                                                           len(Data[Data['NumberOfReconstructions'] > 0]),\n",
    "                                                                           len(Data.Fish.unique()) -6 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('In total, we have %s reconstructions for all the %s datasets'\n",
    "      % (Data['NumberOfReconstructions'].sum(),\n",
    "         len(Data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('On average, each of the %s datasets has about %s reconstructions.'\n",
    "      % (len(Data),\n",
    "         int(round(Data['NumberOfReconstructions'].mean()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop samples which have no reconstructions\n",
    "# Based on https://stackoverflow.com/a/13851602\n",
    "for c, row in Data.iterrows():\n",
    "    if not row['NumberOfReconstructions']:\n",
    "        print('%s contains no PNG files, we drop it for the rest of the notebook' % row.Folder)\n",
    "print('We have %s folders in total' % (len(Data)))\n",
    "print(\"Of which %s folders contain reconstructions (Data['NumberOfReconstructions']>0)\" % (len(Data[Data['NumberOfReconstructions'] > 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the size of the reconstructions\n",
    "Data['ReconstructionSize'] = [[os.path.getsize(rec) for rec in recs] for recs in Data['Reconstructions']]\n",
    "Data['ReconstructionSizeSum'] = [sum(sizes) for sizes in Data['ReconstructionSize']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('In total, the reconstructions are %0.2f GB in size' % (Data['ReconstructionSizeSum'].sum() / 1024 / 1024 / 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('In total, the reconstructions are %0.1f TB in size' % (Data['ReconstructionSizeSum'].sum() / 1024 / 1024 / 1024 / 1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get (nearly) the same size, use\n",
    "````bash\n",
    "find . -iname '*rec0*.png' -print0 | du -ch --files0-from=-\n",
    "````\n",
    "in a Linux console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
