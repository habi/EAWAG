{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle the 'data' of the fishes\n",
    "Wrestle with our data and Mikkis XLS sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import os\n",
    "import glob\n",
    "import pandas\n",
    "import imageio\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "import seaborn\n",
    "import dask\n",
    "import dask_image.imread\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from numcodecs import Blosc\n",
    "import skimage\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask temporarry files go to D:\\tmp\n"
     ]
    }
   ],
   "source": [
    "# Set dask temporary folder\n",
    "# Do this before creating a client: https://stackoverflow.com/a/62804525/323100\n",
    "import tempfile\n",
    "if 'Linux' in platform.system():\n",
    "    tmp = os.path.join(os.sep, 'media', 'habi', 'Fast_SSD')\n",
    "elif 'Darwin' in platform.system():\n",
    "    tmp = tempfile.gettempdir()\n",
    "else:\n",
    "    if 'anaklin' in platform.node():\n",
    "        tmp = os.path.join('F:\\\\')\n",
    "    else:\n",
    "        tmp = os.path.join('D:\\\\')\n",
    "dask.config.set({'temporary_directory': os.path.join(tmp, 'tmp')})\n",
    "print('Dask temporarry files go to %s' % dask.config.get('temporary_directory'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haberthu\\Miniconda3\\lib\\site-packages\\distributed\\node.py:160: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 57555 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Start cluster and client now, after setting tempdir\n",
    "cluster = LocalCluster(n_workers=8)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can seee what DASK is doing at \"http://localhost:57555/status\"\n"
     ]
    }
   ],
   "source": [
    "print('You can seee what DASK is doing at \"http://localhost:%s/status\"' % client.scheduler_info()['services']['dashboard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ignore warnings in the notebook\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure defaults\n",
    "plt.rc('image', cmap='gray', interpolation='nearest')  # Display all images in b&w and with 'nearest' interpolation\n",
    "plt.rcParams['figure.figsize'] = (16, 9)  # Size up figures a bit\n",
    "plt.rcParams['figure.dpi'] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup scale bar defaults\n",
    "plt.rcParams['scalebar.location'] = 'lower right'\n",
    "plt.rcParams['scalebar.frameon'] = False\n",
    "plt.rcParams['scalebar.color'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all plots identically\n",
    "lines = 3\n",
    "# And then do something like\n",
    "# plt.subplot(lines, numpy.ceil(len(Data) / float(lines)), c + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are loading all the data from D:\\Results\\EAWAG\n"
     ]
    }
   ],
   "source": [
    "# Different locations if running either on Linux or Windows\n",
    "FastSSD = False\n",
    "# to speed things up significantly\n",
    "if 'Linux' in platform.system():\n",
    "    if FastSSD:\n",
    "        BasePath = os.path.join(os.sep, 'media', 'habi', 'Fast_SSD')\n",
    "    else:\n",
    "        BasePath = os.path.join(os.sep, 'home', 'habi', '1272')\n",
    "elif 'Darwin' in platform.system():\n",
    "    FastSSD = False\n",
    "    BasePath = os.path.join('/Users/habi/Dev/EAWAG/Data')\n",
    "elif 'Windows' in platform.system():\n",
    "    if FastSSD:\n",
    "        BasePath = os.path.join('F:\\\\')\n",
    "    else:\n",
    "        if 'anaklin' in platform.node():\n",
    "            BasePath = os.path.join('S:\\\\')\n",
    "        else:\n",
    "            BasePath = os.path.join('D:\\\\Results')\n",
    "Root = os.path.join(BasePath, 'EAWAG')\n",
    "print('We are loading all the data from %s' % Root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixelsize(logfile):\n",
    "    \"\"\"Get the pixel size from the scan log file\"\"\"\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Image Pixel' in line and 'Scaled' not in line:\n",
    "                pixelsize = float(line.split('=')[1])\n",
    "    return(pixelsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_projectionsize(logfile):\n",
    "    \"\"\"How big did we set the camera?\"\"\"\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Number Of Rows' in line:\n",
    "                y = int(line.split('=')[1])\n",
    "            if 'Number Of Columns' in line:\n",
    "                x = int(line.split('=')[1])                \n",
    "    return(x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filter(logfile):\n",
    "    \"\"\"Get the filter we used whole scanning from the scan log file\"\"\"\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Filter=' in line:\n",
    "                whichfilter = line.split('=')[1].strip()\n",
    "    return(whichfilter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exposuretime(logfile):\n",
    "    \"\"\"Get the exposure time size from the scan log file\"\"\"\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Exposure' in line:\n",
    "                exposuretime = int(line.split('=')[1])\n",
    "    return(exposuretime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ringartefact(logfile):\n",
    "    \"\"\"Get the ring artefact correction from the  scan log file\"\"\"\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Ring Artifact' in line:\n",
    "                ringartefactcorrection = int(line.split('=')[1])\n",
    "    return(ringartefactcorrection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reconstruction_grayvalue(logfile):\n",
    "    grayvalue = None\n",
    "    \"\"\"How did we map the brightness of the reconstructions?\"\"\"\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Maximum for' in line:\n",
    "                grayvalue = float(line.split('=')[1])\n",
    "    return(grayvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beamhardening(logfile):\n",
    "    \"\"\"Get the beamhardening correction from the  scan log file\"\"\"\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Hardening' in line:\n",
    "                beamhardeningcorrection = int(line.split('=')[1])\n",
    "    return(beamhardeningcorrection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rotationstep(logfile):\n",
    "    \"\"\"Get the rotation step from the scan log file\"\"\"\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Rotation Step' in line:\n",
    "                rotstep = float(line.split('=')[1])\n",
    "    return(rotstep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frameaveraging(logfile):\n",
    "    \"\"\"Get the frame averaging from the scan log file\"\"\"\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Averaging' in line:\n",
    "                avg = line.split('=')[1]\n",
    "    return(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_machine(logfile):\n",
    "    \"\"\"Get the machine we used to scan\"\"\"\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Scanner' in line:\n",
    "                machine = line.split('=')[1].strip()\n",
    "    return(machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scantime(logfile):\n",
    "    \"\"\"How long did we scan?\"\"\"\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Scan duration' in line:\n",
    "                time = line.split('=')[1].strip()\n",
    "    return(pandas.to_timedelta(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacks(logfile):\n",
    "    \"\"\"How many stacks/connected scans did we make?\"\"\"\n",
    "    stacks = 1\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'conn' in line:\n",
    "                stacks = int(line.split('=')[1])\n",
    "    return(stacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scandate(logfile, verbose=False):\n",
    "    \"\"\"When did we scan the fish?\"\"\"\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Study Date and Time' in line:\n",
    "                if verbose:\n",
    "                    print('Found \"date\" line: %s' % line.strip())\n",
    "                datestring = line.split('=')[1].strip().replace('  ', ' ')\n",
    "                if verbose:\n",
    "                    print('The date string is: %s' % datestring)\n",
    "                date = pandas.to_datetime(datestring , format='%d %b %Y %Hh:%Mm:%Ss')\n",
    "                if verbose:\n",
    "                    print('Parsed to: %s' % date)\n",
    "                (date)\n",
    "    return(date.isoformat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_git_hash():\n",
    "    '''\n",
    "    Get the current git hash from the repository.\n",
    "    Based on http://stackoverflow.com/a/949391/323100 and\n",
    "    http://stackoverflow.com/a/18283905/323100\n",
    "    '''\n",
    "    from subprocess import Popen, PIPE\n",
    "    import os\n",
    "    gitprocess = Popen(['git',\n",
    "                        '--git-dir',\n",
    "                        os.path.join(os.getcwd(), '.git'),\n",
    "                        'rev-parse',\n",
    "                        '--short',\n",
    "                        '--verify',\n",
    "                        'HEAD'],\n",
    "                       stdout=PIPE)\n",
    "    (output, _) = gitprocess.communicate()\n",
    "    return output.strip().decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make directory for output\n",
    "# OutPutDir = os.path.join(os.getcwd(), 'Output', get_git_hash())\n",
    "# print('We are saving all the output to %s' % OutPutDir)\n",
    "# os.makedirs(OutPutDir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make us a dataframe for saving all that we need\n",
    "Data = pandas.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get *all* log files\n",
    "# Sort them by time, not name\n",
    "Data['LogFile'] = [f for f in sorted(glob.glob(os.path.join(Root, '**', '*.log'), recursive=True), key=os.path.getmtime)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all folders\n",
    "Data['Folder'] = [os.path.dirname(f) for f in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "- 105005_104015\\proj\\105005_104015~00.log is missing matching reconstructions\n",
      "[]\n",
      "- 105005_104015\\proj\\105005_104015~01.log is missing matching reconstructions\n",
      "[]\n",
      "- 105005_104015\\proj\\105005_104015~02.log is missing matching reconstructions\n",
      "[]\n",
      "- 105005_104015\\proj\\105005_104015~03.log is missing matching reconstructions\n",
      "[]\n",
      "- 105005_104015\\proj\\105005_104015~04.log is missing matching reconstructions\n",
      "[]\n",
      "- 105005_104015\\proj\\105005_104015.log is missing matching reconstructions\n",
      "[]\n",
      "- 104671_156645\\proj\\104671_156645~00.log is missing matching reconstructions\n",
      "[]\n",
      "- 104671_156645\\proj\\104671_156645~01.log is missing matching reconstructions\n",
      "[]\n",
      "- 104671_156645\\proj\\104671_156645~02.log is missing matching reconstructions\n",
      "[]\n",
      "- 104671_156645\\proj\\104671_156645.log is missing matching reconstructions\n"
     ]
    }
   ],
   "source": [
    "# Check for samples which are not yet reconstructed\n",
    "for c, row in Data.iterrows():\n",
    "    # Iterate over every 'proj' folder\n",
    "    if 'proj' in row.Folder:\n",
    "        if not 'TScopy' in row.Folder and not 'PR' in row.Folder:\n",
    "            # If there's nothing with 'rec*' on the same level, then tell us        \n",
    "            if not glob.glob(row.Folder.replace('proj', 'rec')):\n",
    "                print(glob.glob(row.Folder.replace('proj', 'rec')))\n",
    "                print('- %s is missing matching reconstructions' % row.LogFile[len(Root)+1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of all non-rec logfiles\n",
    "for c, row in Data.iterrows():\n",
    "    if 'rec' not in row.Folder:\n",
    "        Data.drop([c], inplace=True)\n",
    "    elif 'rectmp.log' in row.LogFile:\n",
    "        Data.drop([c], inplace=True)\n",
    "# Reset dataframe to something that we would get if we only would have loaded the 'rec' files\n",
    "Data = Data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate us some meaningful colums\n",
    "Data['Fish'] = [l[len(Root)+1:].split(os.sep)[0] for l in Data['LogFile']]\n",
    "Data['Scan'] = [l[len(Root)+1:].split(os.sep)[1] for l in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the file names of the reconstructions\n",
    "Data['Reconstructions'] = [sorted(glob.glob(os.path.join(f, '*rec0*.png'))) for f in Data['Folder']]\n",
    "Data['Number of reconstructions'] = [len(r) for r in Data.Reconstructions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Results\\EAWAG\\103375\\rec_stuck contains no PNG files, we might be currently reconstructing it\n",
      "D:\\Results\\EAWAG\\11965\\rec_rescan\\SubScan1 contains no PNG files, we might be currently reconstructing it\n",
      "D:\\Results\\EAWAG\\11965\\rec_rescan\\SubScan2 contains no PNG files, we might be currently reconstructing it\n",
      "We have 120 folders with reconstructions\n"
     ]
    }
   ],
   "source": [
    "# Drop samples which have not been reconstructed yet\n",
    "# Based on https://stackoverflow.com/a/13851602\n",
    "for c,row in Data.iterrows():\n",
    "    if not row['Number of reconstructions']:\n",
    "        print('%s contains no PNG files, we might be currently reconstructing it' % row.Folder)\n",
    "Data = Data[Data['Number of reconstructions'] > 0]\n",
    "Data.reset_index(drop=True, inplace=True)\n",
    "print('We have %s folders with reconstructions' % (len(Data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get parameters to doublecheck from logfiles\n",
    "Data['Voxelsize'] = [get_pixelsize(log) for log in Data['LogFile']]\n",
    "Data['Filter'] = [get_filter(log) for log in Data['LogFile']]\n",
    "Data['Exposuretime'] = [get_exposuretime(log) for log in Data['LogFile']]\n",
    "Data['Scanner'] = [get_machine(log) for log in Data['LogFile']]\n",
    "Data['Averaging'] = [get_frameaveraging(log) for log in Data['LogFile']]\n",
    "Data['ProjectionSize'] = [get_projectionsize(log) for log in Data['LogFile']]\n",
    "Data['RotationStep'] = [get_rotationstep(log) for log in Data['LogFile']]\n",
    "Data['CameraWindow'] = [round((ps ** 0.5)/100)*100  for ps in Data['ProjectionSize']]\n",
    "Data['Grayvalue'] = [get_reconstruction_grayvalue(log) for log in Data['LogFile']]\n",
    "Data['RingartefactCorrection'] = [get_ringartefact(log) for log in Data['LogFile']]\n",
    "Data['BeamHardeningCorrection'] = [get_beamhardening(log) for log in Data['LogFile']]\n",
    "Data['Scan date'] = [get_scandate(log) for log in Data['LogFile']]\n",
    "Data['Scan time'] = [get_scantime(log) for log in Data['LogFile']]\n",
    "Data['Stacks'] = [get_stacks(log) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Scan time total'] = [ st * stk  for st, stk in zip(Data['Scan time'], Data['Stacks'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://www.geeksforgeeks.org/iterating-over-rows-and-columns-in-pandas-dataframe/\n",
    "# columns = list(Data)\n",
    "# columns.remove('Folder') \n",
    "# columns.remove('Fish')\n",
    "# columns.remove('LogFile')\n",
    "# columns.remove('Reconstructions')\n",
    "# columns.remove('Number of reconstructions')\n",
    "# columns.remove('Grayvalue')\n",
    "# columns.remove('Scan time')\n",
    "# columns.remove('Scan time total')\n",
    "# columns.remove('Scan date')\n",
    "# print(columns)\n",
    "# for col in columns:\n",
    "#     print(col)\n",
    "#     print(Data[col].unique())\n",
    "#     print(80*'-')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check voxel sizes (*rounded* to two after-comma values)\n",
    "# # If different, spit out which values\n",
    "# roundto = 2\n",
    "# if len(Data['Voxelsize'].round(roundto).unique()) > 1:\n",
    "#     print('We scanned all datasets with %s different voxel sizes' % len(Data['Voxelsize'].round(roundto).unique()))\n",
    "#     for vs in sorted(Data['Voxelsize'].round(roundto).unique()):\n",
    "#         print('-', vs, 'um for ', end='')\n",
    "#         for c, row in Data.iterrows():\n",
    "#             if float(vs) == round(row['Voxelsize'], roundto):\n",
    "#                 print(os.path.join(row['Fish'], row['Scan']), end=', ')\n",
    "#         print('')\n",
    "# else:\n",
    "#     print('We scanned all datasets with equal voxel size, namely %s um.' % float(Data['Voxelsize'].round(roundto).unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if len(Data['Grayvalue'].unique()) > 1:\n",
    "#     print('We reconstructed the datasets with different maximum gray values, namely')\n",
    "#     for gv in Data['Grayvalue'].unique():\n",
    "#         print(gv, 'for Samples ', end='')\n",
    "#         for c, row in Data.iterrows():\n",
    "#             if float(gv) == row['Grayvalue']:\n",
    "#                 print(os.path.join(row['Fish'], row['Scan']), end=', ')\n",
    "#         print('')\n",
    "# else:\n",
    "#     print('We reconstructed all datasets with equal maximum gray value, namely %s.' % Data['Grayvalue'].unique()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data[['Fish', 'Scan',\n",
    "#       'Voxelsize', 'Scanner',\n",
    "#       'Scan date', 'CameraWindow', 'RotationStep', 'Averaging',\n",
    "#       'Scan time', 'Stacks', 'Scan time total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total, we scanned for 356 hours and 27 minutes)\n",
      "\t - Of these, we scanned 110 hours and 32 minutes on the SkyScan1272,for 31 scans\n",
      "\t - Of these, we scanned 245 hours and 55 minutes on the SkyScan2214,for 89 scans\n"
     ]
    }
   ],
   "source": [
    "# Get an overview over the total scan time\n",
    "# Nice output based on https://stackoverflow.com/a/8907407/323100\n",
    "total_seconds = int(Data['Scan time total'].sum().total_seconds())\n",
    "hours, remainder = divmod(total_seconds,60*60)\n",
    "minutes, seconds = divmod(remainder,60)\n",
    "print('In total, we scanned for %s hours and %s minutes)' % (hours, minutes))\n",
    "for machine in Data['Scanner'].unique():\n",
    "    total_seconds = int(Data[Data['Scanner'] == machine]['Scan time total'].sum().total_seconds())\n",
    "    hours, remainder = divmod(total_seconds,60*60)\n",
    "    minutes, seconds = divmod(remainder,60)\n",
    "    print('\\t - Of these, we scanned %s hours and %s minutes on the %s,'\n",
    "          'for %s scans' % (hours,\n",
    "                            minutes,\n",
    "                            machine,\n",
    "                            len(Data[Data['Scanner'] == machine])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data[['Fish', 'Scan',\n",
    "      'Voxelsize', 'Scanner',\n",
    "      'Scan date', 'CameraWindow', 'RotationStep', 'Averaging', 'Scan time', 'Stacks' ]].to_excel('Details.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data[['Fish', 'Scan',\n",
    "      'Voxelsize', 'Scanner',\n",
    "      'Scan date', 'CameraWindow',\n",
    "      'RotationStep', 'Averaging', 'Scan time', 'Stacks' ]].to_excel(os.path.join(Root,'Details.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in D:\\Results\\EAWAG\\X_ArchiveFiles\\02.07.2021_CTscanFishList.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Read Mikkis datafile\n",
    "MikkisFile = sorted(glob.glob(os.path.join(Root, 'X_ArchiveFiles', '*CTscanFishList.xlsx')))[0]\n",
    "# Read excel file and use the first column as index\n",
    "print('Reading in %s' % MikkisFile)\n",
    "DataMikki = pandas.read_excel(MikkisFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fishec</th>\n",
       "      <th>FieldID</th>\n",
       "      <th>OtherID</th>\n",
       "      <th>ReplacementID</th>\n",
       "      <th>Length(cm)</th>\n",
       "      <th>TemporaryJar</th>\n",
       "      <th>Genus</th>\n",
       "      <th>Species</th>\n",
       "      <th>Ecology</th>\n",
       "      <th>Scan date</th>\n",
       "      <th>HeadScan</th>\n",
       "      <th>OralJawScan</th>\n",
       "      <th>PharyngealJawScan</th>\n",
       "      <th>OperculumVisible</th>\n",
       "      <th>DataUploaded</th>\n",
       "      <th>QualityChecked</th>\n",
       "      <th>ScanComments</th>\n",
       "      <th>SpecimenReturned</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt; 7</td>\n",
       "      <td>&lt; 7cm</td>\n",
       "      <td>\"Astatotilapia\"</td>\n",
       "      <td>nubila swamp blue</td>\n",
       "      <td>insectivore</td>\n",
       "      <td>2021-02-08T12:25:19</td>\n",
       "      <td>no 20um headscan</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no 20um headscan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2-3 inner row of tricuspid teeth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt; 7</td>\n",
       "      <td>&lt; 7cm</td>\n",
       "      <td>\"Astatotilapia\"</td>\n",
       "      <td>nubila swamp blue</td>\n",
       "      <td>insectivore</td>\n",
       "      <td>2021-02-08T14:24:12</td>\n",
       "      <td>no 20um headscan</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no 20um headscan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2-3 inner row of tricuspid teeth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt; 7</td>\n",
       "      <td>&lt; 7cm</td>\n",
       "      <td>Enterochromis I</td>\n",
       "      <td>cinctus (St. E)</td>\n",
       "      <td>detritivore</td>\n",
       "      <td>2021-02-04T11:21:23</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>not complete</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pharyngeal jaw not complete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt; 7</td>\n",
       "      <td>&lt; 7cm</td>\n",
       "      <td>Enterochromis I</td>\n",
       "      <td>cinctus (St. E)</td>\n",
       "      <td>detritivore</td>\n",
       "      <td>2021-02-04T13:30:11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt; 7</td>\n",
       "      <td>&lt; 7cm</td>\n",
       "      <td>Incertae sedis</td>\n",
       "      <td>thick skin</td>\n",
       "      <td>insectivore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bad segmentation quality</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fishec FieldID OtherID ReplacementID Length(cm) TemporaryJar  \\\n",
       "0  103635     NaN     NaN           NaN        < 7        < 7cm   \n",
       "1  103635     NaN     NaN           NaN        < 7        < 7cm   \n",
       "2  104016     NaN     NaN           NaN        < 7        < 7cm   \n",
       "3  104016     NaN     NaN           NaN        < 7        < 7cm   \n",
       "4   14298     NaN     NaN           NaN        < 7        < 7cm   \n",
       "\n",
       "             Genus            Species      Ecology            Scan date  \\\n",
       "0  \"Astatotilapia\"  nubila swamp blue  insectivore  2021-02-08T12:25:19   \n",
       "1  \"Astatotilapia\"  nubila swamp blue  insectivore  2021-02-08T14:24:12   \n",
       "2  Enterochromis I    cinctus (St. E)  detritivore  2021-02-04T11:21:23   \n",
       "3  Enterochromis I    cinctus (St. E)  detritivore  2021-02-04T13:30:11   \n",
       "4   Incertae sedis         thick skin  insectivore                  NaN   \n",
       "\n",
       "           HeadScan OralJawScan PharyngealJawScan  OperculumVisible  \\\n",
       "0  no 20um headscan         yes               yes  no 20um headscan   \n",
       "1  no 20um headscan         yes               yes  no 20um headscan   \n",
       "2                no         yes      not complete                no   \n",
       "3               NaN         NaN               NaN               NaN   \n",
       "4                no         yes               NaN                no   \n",
       "\n",
       "  DataUploaded QualityChecked                      ScanComments  \\\n",
       "0          NaN            NaN  2-3 inner row of tricuspid teeth   \n",
       "1          NaN            NaN  2-3 inner row of tricuspid teeth   \n",
       "2          NaN            NaN       pharyngeal jaw not complete   \n",
       "3          NaN            NaN                               NaN   \n",
       "4          NaN            NaN          bad segmentation quality   \n",
       "\n",
       "   SpecimenReturned Comments  \n",
       "0               NaN      NaN  \n",
       "1               NaN      NaN  \n",
       "2               NaN      NaN  \n",
       "3               NaN      NaN  \n",
       "4               NaN      NaN  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataMikki.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An sample containing \"13420\" (fish 13420/FEMALE? - NEEDS CHECKING WITH OLE/) should be in jar \"length=nan cm\" (Mark6))\n"
     ]
    }
   ],
   "source": [
    "# Find the fish we need to scan and display the jar\n",
    "fish = '13420'\n",
    "\n",
    "# Where is it?    \n",
    "for d, row in DataMikki.iterrows():\n",
    "    if (str(fish).lower() in str(row.Fishec).lower()) or \\\n",
    "    (str(fish).lower() in str(row.FieldID).lower()) or \\\n",
    "    (str(fish).lower() in str(row.OtherID).lower()) or \\\n",
    "    (str(fish).lower() in str(row.ReplacementID).lower()):\n",
    "        foundfishes = (row.Fishec, row.FieldID, row.OtherID, row.ReplacementID)\n",
    "        # remove nan from the list of hits\n",
    "        foundfishes = [str(x).lower() for x in foundfishes if pandas.isnull(x) == False]\n",
    "        print('An sample containing \"%s\" (fish ' % fish, end='')\n",
    "        \n",
    "        # Did we scan it already?\n",
    "        for found in foundfishes:\n",
    "            print(found.upper(), end='/')\n",
    "              \n",
    "              \n",
    "        print(') should be in jar \"length=%s cm\" (%s))' % (row['Length(cm)'],\n",
    "                                                         row['TemporaryJar']))\n",
    "  \n",
    "\n",
    "        try:\n",
    "            print('A sample \"%s\" was scanned on %s' % (found.upper(),\n",
    "                                                       Data[Data['Fish'].str.lower()==found]['Scan date'].values[0]))\n",
    "        except IndexError:\n",
    "            pass\n",
    "            #print('Fish %s was not scanned yet' % found)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101    2021-08-23T10:26:31\n",
       "Name: Scan date, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data[Data['Fish']=='12849']['Scan date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a text file for each rec-folder, in which we can note what's going on with the fish\n",
    "for c,row in Data.iterrows():\n",
    "    outputfile = os.path.join(os.path.dirname(row.Folder), row.Fish + '.' + os.path.basename(row.Folder) + '.md')\n",
    "    if not os.path.exists(outputfile):\n",
    "        with open(outputfile, 'w', encoding='utf-8') as f:\n",
    "            f.write('# Fish %s, Scan %s\\n\\n' % (row.Fish, row.Scan))\n",
    "            f.write('This fish was scanned on %s on the %s, with a voxel size of %s μm.\\n\\n'\n",
    "                    % (row['Scan date'], row.Scanner, numpy.round(row.Voxelsize, 2)))\n",
    "            f.write('## Comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogFile</th>\n",
       "      <th>Folder</th>\n",
       "      <th>Fish</th>\n",
       "      <th>Scan</th>\n",
       "      <th>Reconstructions</th>\n",
       "      <th>Number of reconstructions</th>\n",
       "      <th>Voxelsize</th>\n",
       "      <th>Filter</th>\n",
       "      <th>Exposuretime</th>\n",
       "      <th>Scanner</th>\n",
       "      <th>...</th>\n",
       "      <th>ProjectionSize</th>\n",
       "      <th>RotationStep</th>\n",
       "      <th>CameraWindow</th>\n",
       "      <th>Grayvalue</th>\n",
       "      <th>RingartefactCorrection</th>\n",
       "      <th>BeamHardeningCorrection</th>\n",
       "      <th>Scan date</th>\n",
       "      <th>Scan time</th>\n",
       "      <th>Stacks</th>\n",
       "      <th>Scan time total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:\\Results\\EAWAG\\103908\\jaw\\rec\\103908__rec.log</td>\n",
       "      <td>D:\\Results\\EAWAG\\103908\\jaw\\rec</td>\n",
       "      <td>103908</td>\n",
       "      <td>jaw</td>\n",
       "      <td>[D:\\Results\\EAWAG\\103908\\jaw\\rec\\103908__rec00...</td>\n",
       "      <td>1535</td>\n",
       "      <td>5.000014</td>\n",
       "      <td>Al 0.5mm</td>\n",
       "      <td>1162</td>\n",
       "      <td>SkyScan1272</td>\n",
       "      <td>...</td>\n",
       "      <td>4021280</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.118860</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-11-03T12:34:39</td>\n",
       "      <td>0 days 01:35:36</td>\n",
       "      <td>1</td>\n",
       "      <td>0 days 01:35:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:\\Results\\EAWAG\\Teeth\\W\\rec_al0.25\\W_rec.log</td>\n",
       "      <td>D:\\Results\\EAWAG\\Teeth\\W\\rec_al0.25</td>\n",
       "      <td>Teeth</td>\n",
       "      <td>W</td>\n",
       "      <td>[D:\\Results\\EAWAG\\Teeth\\W\\rec_al0.25\\W_rec0000...</td>\n",
       "      <td>101</td>\n",
       "      <td>2.999931</td>\n",
       "      <td>Al 0.25mm</td>\n",
       "      <td>1985</td>\n",
       "      <td>SkyScan1272</td>\n",
       "      <td>...</td>\n",
       "      <td>1782144</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1300</td>\n",
       "      <td>0.277898</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-10T13:19:28</td>\n",
       "      <td>0 days 01:16:08</td>\n",
       "      <td>1</td>\n",
       "      <td>0 days 01:16:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:\\Results\\EAWAG\\Teeth\\W\\rec_nofilter\\W_rec.log</td>\n",
       "      <td>D:\\Results\\EAWAG\\Teeth\\W\\rec_nofilter</td>\n",
       "      <td>Teeth</td>\n",
       "      <td>W</td>\n",
       "      <td>[D:\\Results\\EAWAG\\Teeth\\W\\rec_nofilter\\W_rec00...</td>\n",
       "      <td>101</td>\n",
       "      <td>2.999931</td>\n",
       "      <td>No Filter</td>\n",
       "      <td>711</td>\n",
       "      <td>SkyScan1272</td>\n",
       "      <td>...</td>\n",
       "      <td>1782144</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1300</td>\n",
       "      <td>0.638647</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-10T10:30:18</td>\n",
       "      <td>0 days 00:35:29</td>\n",
       "      <td>1</td>\n",
       "      <td>0 days 00:35:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:\\Results\\EAWAG\\Teeth\\P\\rec_al0.25\\P_rec.log</td>\n",
       "      <td>D:\\Results\\EAWAG\\Teeth\\P\\rec_al0.25</td>\n",
       "      <td>Teeth</td>\n",
       "      <td>P</td>\n",
       "      <td>[D:\\Results\\EAWAG\\Teeth\\P\\rec_al0.25\\P_rec0000...</td>\n",
       "      <td>151</td>\n",
       "      <td>2.999931</td>\n",
       "      <td>Al 0.25mm</td>\n",
       "      <td>1985</td>\n",
       "      <td>SkyScan1272</td>\n",
       "      <td>...</td>\n",
       "      <td>1782144</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1300</td>\n",
       "      <td>0.326348</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-10T14:59:13</td>\n",
       "      <td>0 days 01:16:16</td>\n",
       "      <td>1</td>\n",
       "      <td>0 days 01:16:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:\\Results\\EAWAG\\Teeth\\P\\rec_nofilter\\P_rec.log</td>\n",
       "      <td>D:\\Results\\EAWAG\\Teeth\\P\\rec_nofilter</td>\n",
       "      <td>Teeth</td>\n",
       "      <td>P</td>\n",
       "      <td>[D:\\Results\\EAWAG\\Teeth\\P\\rec_nofilter\\P_rec00...</td>\n",
       "      <td>151</td>\n",
       "      <td>2.999931</td>\n",
       "      <td>No Filter</td>\n",
       "      <td>711</td>\n",
       "      <td>SkyScan1272</td>\n",
       "      <td>...</td>\n",
       "      <td>1782144</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1300</td>\n",
       "      <td>0.721731</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-10T16:46:29</td>\n",
       "      <td>0 days 00:35:28</td>\n",
       "      <td>1</td>\n",
       "      <td>0 days 00:35:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           LogFile  \\\n",
       "0  D:\\Results\\EAWAG\\103908\\jaw\\rec\\103908__rec.log   \n",
       "1    D:\\Results\\EAWAG\\Teeth\\W\\rec_al0.25\\W_rec.log   \n",
       "2  D:\\Results\\EAWAG\\Teeth\\W\\rec_nofilter\\W_rec.log   \n",
       "3    D:\\Results\\EAWAG\\Teeth\\P\\rec_al0.25\\P_rec.log   \n",
       "4  D:\\Results\\EAWAG\\Teeth\\P\\rec_nofilter\\P_rec.log   \n",
       "\n",
       "                                  Folder    Fish Scan  \\\n",
       "0        D:\\Results\\EAWAG\\103908\\jaw\\rec  103908  jaw   \n",
       "1    D:\\Results\\EAWAG\\Teeth\\W\\rec_al0.25   Teeth    W   \n",
       "2  D:\\Results\\EAWAG\\Teeth\\W\\rec_nofilter   Teeth    W   \n",
       "3    D:\\Results\\EAWAG\\Teeth\\P\\rec_al0.25   Teeth    P   \n",
       "4  D:\\Results\\EAWAG\\Teeth\\P\\rec_nofilter   Teeth    P   \n",
       "\n",
       "                                     Reconstructions  \\\n",
       "0  [D:\\Results\\EAWAG\\103908\\jaw\\rec\\103908__rec00...   \n",
       "1  [D:\\Results\\EAWAG\\Teeth\\W\\rec_al0.25\\W_rec0000...   \n",
       "2  [D:\\Results\\EAWAG\\Teeth\\W\\rec_nofilter\\W_rec00...   \n",
       "3  [D:\\Results\\EAWAG\\Teeth\\P\\rec_al0.25\\P_rec0000...   \n",
       "4  [D:\\Results\\EAWAG\\Teeth\\P\\rec_nofilter\\P_rec00...   \n",
       "\n",
       "   Number of reconstructions  Voxelsize     Filter  Exposuretime      Scanner  \\\n",
       "0                       1535   5.000014   Al 0.5mm          1162  SkyScan1272   \n",
       "1                        101   2.999931  Al 0.25mm          1985  SkyScan1272   \n",
       "2                        101   2.999931  No Filter           711  SkyScan1272   \n",
       "3                        151   2.999931  Al 0.25mm          1985  SkyScan1272   \n",
       "4                        151   2.999931  No Filter           711  SkyScan1272   \n",
       "\n",
       "   ... ProjectionSize  RotationStep  CameraWindow  Grayvalue  \\\n",
       "0  ...        4021280           0.2          2000   0.118860   \n",
       "1  ...        1782144           0.4          1300   0.277898   \n",
       "2  ...        1782144           0.4          1300   0.638647   \n",
       "3  ...        1782144           0.4          1300   0.326348   \n",
       "4  ...        1782144           0.4          1300   0.721731   \n",
       "\n",
       "   RingartefactCorrection  BeamHardeningCorrection            Scan date  \\\n",
       "0                       7                        0  2020-11-03T12:34:39   \n",
       "1                       5                        0  2020-12-10T13:19:28   \n",
       "2                       5                        0  2020-12-10T10:30:18   \n",
       "3                      14                        0  2020-12-10T14:59:13   \n",
       "4                       5                        0  2020-12-10T16:46:29   \n",
       "\n",
       "        Scan time Stacks  Scan time total  \n",
       "0 0 days 01:35:36      1  0 days 01:35:36  \n",
       "1 0 days 01:16:08      1  0 days 01:16:08  \n",
       "2 0 days 00:35:29      1  0 days 00:35:29  \n",
       "3 0 days 01:16:16      1  0 days 01:16:16  \n",
       "4 0 days 00:35:28      1  0 days 00:35:28  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
